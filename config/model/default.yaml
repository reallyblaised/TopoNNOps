# Default model configuration
input_dim: 9  # Will be overridden by actual feature count
layer_dims: [32, 64, 32]
dropout_rate: 0.2
batch_norm: true
activation_fn: "relu"
l1_factor: 0.01
residual: false
init_method: "xavier_uniform"